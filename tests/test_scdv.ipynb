{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SCDVクラスのテスト"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# import reload 用\n",
    "import importlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# error display\n",
    "# target_name 間違っている出力の名前\n",
    "def error_display(test_set, true_set, target_name=\"\"):\n",
    "    return target_name + \" different. test setting : {0}, true settings : {1}\".format(test_set, true_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## クラスの記載"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scdv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 再import \n",
    "importlib.reload(scdv)\n",
    "from scdv import SCDV\n",
    "from scdv import Word\n",
    "from scdv import Document"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## テスト"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Word.match のテスト\n",
    "def test_Word_match():\n",
    "    word=\"A\"\n",
    "    model = Word(word)\n",
    "    assert model.match(word), \"word name \" + error_display(word, model.name)\n",
    "    \n",
    "    # 異なる場合\n",
    "    word_notMatch = \"b\"\n",
    "    assert ~model.match(word_notMatch), \"word name \" + error_display(word_notMatch, model.name)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_Word_match()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Word の get_name のテスト\n",
    "def test_Word_get_name():\n",
    "    name = \"a\"\n",
    "    word = Word(name)\n",
    "    assert word.get_name() == name, error_display(word.get_name(), name, \"get_name\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_Word_get_name()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set_idf のテスト\n",
    "def test_Word_set_idf():\n",
    "    name = \"apple\"\n",
    "    idf = 0.3\n",
    "    \n",
    "    word = Word(name)\n",
    "    word.set_idf(idf)\n",
    "    \n",
    "    assert word.get_idf() == idf, error_display(word.get_idf(), idf, \"idf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_Word_set_idf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calc_clustered_vector のテスト\n",
    "def test_Word_calc_clustered_vector():\n",
    "    name = \"apple\"\n",
    "    idf = 0.3\n",
    "    vector = np.array([2,4,2,1])\n",
    "    cluster_idx = 2\n",
    "    cluster_probability = np.array([0.1, 0.7, 0.2])\n",
    "    \n",
    "    word = Word(name)\n",
    "    word.set_vector(vector)\n",
    "    word.set_idf(idf)\n",
    "    word.set_cluster_idx(cluster_idx)\n",
    "    word.set_cluster_probability(cluster_probability)\n",
    "    \n",
    "    clustered_vector = word.calc_clustered_vector()\n",
    "    \n",
    "    assert clustered_vector.shape[0] == vector.shape[0]*cluster_probability.shape[0], error_display(clustered_vector.shape[0], vector.shape[0]*cluster_probability.shape[0], \"dimension of clustered vector\")\n",
    "    # 各値が等しいか確認する\n",
    "    for idx_cluster_probability, prob in enumerate(cluster_probability):\n",
    "        for idx_vector, value in enumerate(vector):\n",
    "            test_value = clustered_vector[idx_vector+idx_cluster_probability*vector.shape[0]]\n",
    "            true_value = idf*value*prob\n",
    "            assert test_value == true_value, error_display(test_value, true_value, \"value of clustered_vector\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_Word_calc_clustered_vector()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SCDV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SCDVのコンストラクタのテスト\n",
    "def test_SCDV_constract():\n",
    "    num_cluster=10\n",
    "    random_seed = 1\n",
    "    threshold = 0.1\n",
    "    embedding_dimension = 300\n",
    "    \n",
    "    scdv = SCDV(num_cluster, random_seed, threshold, embedding_dimension)\n",
    "    \n",
    "    assert scdv.num_cluster == num_cluster, \"num_cluster \" + error_display(scdv.num_cluster, num_cluster)\n",
    "    assert scdv.random_seed == random_seed, \"num_cluster \" + error_display(scdv.random_seed, random_seed)\n",
    "    assert scdv.threshold == threshold, \"threshold \" + error_display(scdv.threshold, threshold)\n",
    "    assert scdv.embedding_dimension == embedding_dimension, \"embedding_dimension \" + error_display(scdv.embedding_dimension, embedding_dimension)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_SCDV_constract()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove_vocabulary のテスト\n",
    "def test_SCDV_remove_vocabulary():\n",
    "    lst_lst_word = [[\"a\", \"b\"], [\"c\", \"d\", \"e\", \"\"], [\"a\"]]\n",
    "    remove_word = \"a\"\n",
    "    \n",
    "    model = SCDV()\n",
    "    model.set_vocabulary(lst_lst_word)\n",
    "    model.remove_vocabulary(remove_word)\n",
    "    \n",
    "    lst_answer = []\n",
    "    for lst_word in lst_lst_word:\n",
    "        lst_answer += lst_word\n",
    "    lst_answer = list(set(lst_answer))\n",
    "    lst_answer.remove(remove_word)\n",
    "    \n",
    "#     print(lst_answer)\n",
    "#     print(model.get_vocabulary())\n",
    "    \n",
    "    # 削除したい単語が消えているか確認\n",
    "    assert remove_word not in model.get_vocabulary(), \"removed word {0} is exist in vocab.\".format(remove_word)\n",
    "    \n",
    "    # 削除したくない単語が消えていないか確認\n",
    "    for ans in lst_answer:\n",
    "        assert ans in model.get_vocabulary(), \"{0} is not exist in vocab.\".format(ans)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_SCDV_remove_vocabulary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set_vocablary のテスト\n",
    "def test_SCDV_set_vocabulary():\n",
    "    lst_lst_word = [[\"a\", \"b\"], [\"c\", \"d\", \"e\", \"\"], [\"a\"]]\n",
    "    lst_word = []\n",
    "    for lst_input in lst_lst_word:\n",
    "        lst_word+=lst_input\n",
    "    \n",
    "    model = SCDV()\n",
    "    model.set_vocabulary(lst_lst_word)\n",
    "    \n",
    "    # 語彙の多さは同じか\n",
    "    assert len(model.vocabulary) == len(set(lst_word)), error_display(len(model.set_vocabulary), 4, \"num of vocab\")\n",
    "    \n",
    "    # 各単語は語彙に登録されているか\n",
    "    for word in lst_word:\n",
    "        assert word in [word_vocab.name for word_vocab in model.vocabulary], \"word \" + word + \" is not in vocabulary.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_SCDV_set_vocabulary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### word2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make_word2VecModel のテスト\n",
    "def test_SCDV_make_word2VecModel():\n",
    "    lst_lst_word = [[\"a\", \"b\"], [\"c\", \"d\", \"e\", \"\"], [\"a\"]]\n",
    "    embedding_dimension = 100\n",
    "    \n",
    "    model = SCDV(embedding_dimension=embedding_dimension)\n",
    "    model.set_vocabulary(lst_lst_word)\n",
    "    \n",
    "    # word2vec 作成\n",
    "    model.make_word2VecModel(lst_lst_word)\n",
    "    \n",
    "    vec_model = model.word2vec\n",
    "    \n",
    "    # 全単語に対してベクトルが定義されているか確認する\n",
    "    for word in model.get_vocabulary():\n",
    "        try:\n",
    "            vec_model[word]\n",
    "        except NameError:\n",
    "            assert False, \"Word '{0}' is not exist.\".format(word)\n",
    "        \n",
    "    # 埋め込み次元数は等しいか確認する\n",
    "    assert vec_model.wv.syn0.shape[1] == embedding_dimension, error_display(vec_model.syn0.shape[1], embedding_dimension, \"embedding_dimension\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training word2Vec model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/ph6/lib/python3.6/site-packages/ipykernel_launcher.py:17: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "/opt/anaconda3/envs/ph6/lib/python3.6/site-packages/ipykernel_launcher.py:22: DeprecationWarning: Call to deprecated `syn0` (Attribute will be removed in 4.0.0, use self.vectors instead).\n"
     ]
    }
   ],
   "source": [
    "test_SCDV_make_word2VecModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set_word2VecModel のテスト\n",
    "def test_SCDV_set_word2VecModel():\n",
    "    lst_lst_word = [[\"a\", \"b\"], [\"c\", \"d\", \"e\", \"\"], [\"a\"]]\n",
    "    \n",
    "    model = SCDV()\n",
    "    model.set_vocabulary(lst_lst_word)\n",
    "    \n",
    "    # word2vec 作成\n",
    "    model.make_word2VecModel(lst_lst_word, min_word_count=2)\n",
    "    # set\n",
    "    model.set_word2Vec()\n",
    "    \n",
    "    vec_model = model.word2vec\n",
    "    \n",
    "#     print(model.get_vocabulary())\n",
    "    \n",
    "    # vocabulary 中の全単語に対してベクトルが定義されているか確認する\n",
    "    # 定義されていない単語は vocabulary から削除されているはずなのででない\n",
    "    for word in model.vocabulary:\n",
    "        try:\n",
    "            word.get_vector()\n",
    "            \n",
    "            # モデルにおけるベクトルとWord class におけるベクトルは等しいか確認する\n",
    "            assert (vec_model[word.get_name()] == word.get_vector()).all, \"'{0}' vector is different betweend the one of word2vec model and the other of class Word.\".format(word.get_name())\n",
    "        except NameError:\n",
    "            assert False, \"Word vector '{0}' is not exist.\".format(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training word2Vec model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/ph6/lib/python3.6/site-packages/ipykernel_launcher.py:24: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n"
     ]
    }
   ],
   "source": [
    "test_SCDV_set_word2VecModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get_word2vec のテスト\n",
    "def test_SCDV_get_word2Vec():\n",
    "    lst_lst_word = [[\"a\", \"b\"], [\"c\", \"d\", \"e\", \"\"], [\"a\"]]\n",
    "    embedding_dimension = 100\n",
    "    \n",
    "    model = SCDV(embedding_dimension=embedding_dimension)\n",
    "    model.set_vocabulary(lst_lst_word)\n",
    "    \n",
    "    # word2vec 作成\n",
    "    model.make_word2VecModel(lst_lst_word)\n",
    "    # set\n",
    "    model.set_word2Vec()\n",
    "    # get\n",
    "    word_vectors = model.get_word2Vec()\n",
    "\n",
    "#     print(word_vectors)\n",
    "    assert word_vectors.shape[0] == len(model.get_vocabulary()), error_display(word_vectors.shape[0], len(model.get_vocabulary()), \"num of word\")\n",
    "    assert word_vectors.shape[1] == embedding_dimension, error_display(word_vectors.shape[1], embedding_dimension, \"embedding dimension\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training word2Vec model...\n"
     ]
    }
   ],
   "source": [
    "test_SCDV_get_word2Vec()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calc_cluster_probability のテスト\n",
    "def test_SCDV_calc_cluster_probability():\n",
    "    lst_lst_word = [[\"a\", \"b\"], [\"c\", \"d\", \"e\", \"\"], [\"a\"]]\n",
    "    num_cluster = 3\n",
    "    \n",
    "    model = SCDV(num_cluster=num_cluster)\n",
    "    model.set_vocabulary(lst_lst_word)\n",
    "    \n",
    "    # word2vec 作成\n",
    "    model.make_word2VecModel(lst_lst_word)\n",
    "    # set\n",
    "    model.set_word2Vec()\n",
    "    \n",
    "    # clustering model の作成\n",
    "    model.make_clusterModel()\n",
    "    \n",
    "    idx, idx_proba = model.calc_cluster_probability()\n",
    "    \n",
    "    assert idx_proba.shape[1] == num_cluster, error_display(idx_proba[1], num_cluster, \"num of cluster\")\n",
    "    assert sum([1 if idx_cluster >= num_cluster else 0 for idx_cluster in idx])==0, \"out of cluster num\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training word2Vec model...\n",
      "Training clustering model...\n"
     ]
    }
   ],
   "source": [
    "test_SCDV_calc_cluster_probability()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set_cluster のテスト\n",
    "def test_SCDV_set_cluster():\n",
    "    lst_lst_word = [[\"a\", \"b\"], [\"c\", \"d\", \"e\", \"\"], [\"a\"]]\n",
    "    num_cluster = 3\n",
    "    \n",
    "    model = SCDV(num_cluster=num_cluster)\n",
    "    model.set_vocabulary(lst_lst_word)\n",
    "    \n",
    "    # word2vec 作成\n",
    "    model.make_word2VecModel(lst_lst_word)\n",
    "    # set\n",
    "    model.set_word2Vec()\n",
    "    \n",
    "    # clustering model の作成\n",
    "    model.make_clusterModel()\n",
    "    cluster_model = model.get_clusterModel()\n",
    "    model.set_cluster()\n",
    "    idx_cluster, idx_proba = model.calc_cluster_probability()\n",
    "    \n",
    "    for idx, word in enumerate(model.vocabulary):\n",
    "        assert word.get_cluster_idx() == idx_cluster[idx], error_display(word.get_cluster_idx(), idx_cluster, \"cluster id\")\n",
    "        assert (word.get_cluster_probability==idx_proba).all, \"the probability of cluster membership is different for {0}\".format(word.name) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training word2Vec model...\n",
      "Training clustering model...\n"
     ]
    }
   ],
   "source": [
    "test_SCDV_set_cluster()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calc_idf_by_word のテスト\n",
    "def test_SCDV_calc_idf_by_word():\n",
    "    lst_lst_word = [[\"apple\", \"banana\"], [\"corch\", \"banana\", \"empty\", \"\"], [\"apple\"]]\n",
    "    \n",
    "    model = SCDV()\n",
    "    model.set_vocabulary(lst_lst_word)\n",
    "    \n",
    "    # idf値算出\n",
    "    feature_names, _ = model.calc_idf_by_word(lst_lst_word)\n",
    "    \n",
    "    # 各単語のidf値はvocaburalyに存在する単語か\n",
    "    for word in feature_names:\n",
    "        assert word in model.get_vocabulary(), \"The idf value of {0} is not calculated.\".format(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_SCDV_calc_idf_by_word()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set_idf のテスト\n",
    "def test_SCDV_set_idf():\n",
    "    lst_lst_word = [[\"apple\", \"banana\"], [\"corch\", \"banana\", \"empty\", \"\"], [\"apple\", \"I\"]]\n",
    "    \n",
    "    model = SCDV()\n",
    "    model.set_vocabulary(lst_lst_word)\n",
    "    \n",
    "    # idf 値算出\n",
    "    feature_names, idf = model.calc_idf_by_word(lst_lst_word)\n",
    "    # idf 値セット\n",
    "    model.set_idf(feature_names, idf)\n",
    "    \n",
    "#     print(model.get_vocabulary())\n",
    "    \n",
    "    # idf値が設定されている vocabulary に対し、値は一致するか\n",
    "    for word in model.vocabulary:\n",
    "        idf_word = word.get_idf()\n",
    "        # idf値が設定されている場合に値のチェック\n",
    "        if idf_word != 0:\n",
    "            assert (idf_word == idf[feature_names.index(word.get_name())]).all, \"The idf value of {0} is different.\".format(word.get_name())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_SCDV_set_idf()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### clustered vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make_clustered_vector のテスト\n",
    "def test_SCDV_make_clustered_vector():\n",
    "    lst_lst_word = [[\"apple\", \"banana\"], [\"corch\", \"banana\", \"empty\", \"\"], [\"apple\"]]\n",
    "    num_cluster = 3\n",
    "    \n",
    "    model = SCDV(num_cluster = num_cluster)\n",
    "    model.set_vocabulary(lst_lst_word)\n",
    "    \n",
    "    # word2vec 作成\n",
    "    model.make_word2VecModel(lst_lst_word)\n",
    "    model.set_word2Vec()\n",
    "    \n",
    "    # clustering model の作成\n",
    "    model.make_clusterModel()\n",
    "    model.set_cluster()\n",
    "    \n",
    "    # idf 値算出・セット\n",
    "    feature_names, idf = model.calc_idf_by_word(lst_lst_word)\n",
    "    model.set_idf(feature_names, idf)\n",
    "    \n",
    "    # clustered_vector の算出\n",
    "    model.make_clustered_vector()\n",
    "    \n",
    "    # clustered vector の次元が正しいか確認\n",
    "#     for word in model.vocabulary:\n",
    "#         assert word.get_clustered_vector() == "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training word2Vec model...\n",
      "Training clustering model...\n"
     ]
    }
   ],
   "source": [
    "test_SCDV_make_clustered_vector()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Document の平均スパースベクトル"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set_documentのテスト\n",
    "def test_SCDV_set_document():\n",
    "    lst_lst_word = [[\"apple\", \"banana\"], [\"corch\", \"banana\", \"empty\", \"\"], [\"apple\"]]\n",
    "    remove_word= \"banana\"\n",
    "    \n",
    "    model = SCDV()\n",
    "    model.set_vocabulary(lst_lst_word)\n",
    "    model.remove_vocabulary(remove_word)\n",
    "    model.set_documents(lst_lst_word)\n",
    "    \n",
    "    # document の数は一致するか\n",
    "    assert len(lst_lst_word) == len(model.documents), \"num of documents \" + error_display(len(lst_lst_word), len(model.documents))\n",
    "    # 各単語は一致するか\n",
    "    for idx, lst_word in enumerate(lst_lst_word):\n",
    "        document = model.documents[idx]\n",
    "        # 削除対象の単語を抜く\n",
    "        if remove_word in lst_word:\n",
    "            lst_word.remove(remove_word)\n",
    "        assert len(document.words)==len(lst_word), \"num of words \" + error_display(len(document.words), len(lst_word))\n",
    "        \n",
    "#         for idx_word, word in enumerate(document.words):\n",
    "#             assert word.match(lst_word[idx_word]), error_display(word.name, lst_word[idx_word], \"word\")\n",
    "        for word in lst_word:\n",
    "            assert document.isExist_word(word), \"{0} is not exist in document.\".format(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_SCDV_set_document()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make_meanDocumentVector のテスト\n",
    "def test_SCDV_make_meanDocumentVector():\n",
    "    lst_lst_word = [[\"apple\", \"banana\"], [\"corch\", \"banana\", \"empty\", \"\"], [\"apple\"]]\n",
    "    num_cluster = 3\n",
    "    embedding_dimension = 100\n",
    "    \n",
    "    model = SCDV(num_cluster=num_cluster,embedding_dimension=embedding_dimension)\n",
    "    model.set_vocabulary(lst_lst_word)\n",
    "    \n",
    "    # word2vec 作成\n",
    "    model.make_word2VecModel(lst_lst_word)\n",
    "    model.set_word2Vec()\n",
    "    \n",
    "    # cluster 作成\n",
    "    model.make_clusterModel()\n",
    "    model.set_cluster()\n",
    "    \n",
    "    # idf 値算出\n",
    "    feature_names, idf = model.calc_idf_by_word(lst_lst_word)\n",
    "    model.set_idf(feature_names, idf)\n",
    "    \n",
    "    # clustered_vector の算出\n",
    "    model.make_clustered_vector()\n",
    "    \n",
    "    # Document セット\n",
    "    model.set_documents(lst_lst_word)\n",
    "    \n",
    "    # 平均ベクトルセット\n",
    "    model.make_meanDocumentVector()\n",
    "    \n",
    "    # 各ベクトルの次元が一致するか確認\n",
    "    for document in model.get_documents():\n",
    "        assert document.get_meanWordVector().shape[0] == num_cluster*embedding_dimension, error_display(document.get_meanWordVector().shape[0], num_cluster*embedding_dimension, \"dimension of mean vector\")\n",
    "        try:\n",
    "            document.get_meanWordVector().shape[1]\n",
    "            assert False, \"dimension is out of range\"\n",
    "        except:\n",
    "            continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training word2Vec model...\n",
      "Training clustering model...\n"
     ]
    }
   ],
   "source": [
    "test_SCDV_make_meanDocumentVector()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 再import \n",
    "importlib.reload(scdv)\n",
    "from scdv import SCDV\n",
    "from scdv import Word\n",
    "from scdv import Document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make_sparceDocumentVector のテスト\n",
    "def test_SCDV_make_sparceDocumentVector():\n",
    "    lst_lst_word = [[\"apple\", \"banana\"], [\"corch\", \"banana\", \"empty\", \"\"], [\"apple\"]]\n",
    "    num_cluster = 3\n",
    "    embedding_dimension = 100\n",
    "    \n",
    "    model = SCDV(num_cluster=num_cluster,embedding_dimension=embedding_dimension)\n",
    "    model.set_vocabulary(lst_lst_word)\n",
    "    \n",
    "    # word2vec 作成\n",
    "    model.make_word2VecModel(lst_lst_word)\n",
    "    model.set_word2Vec()\n",
    "    \n",
    "    # cluster 作成\n",
    "    model.make_clusterModel()\n",
    "    model.set_cluster()\n",
    "    \n",
    "    # idf 値算出\n",
    "    feature_names, idf = model.calc_idf_by_word(lst_lst_word)\n",
    "    model.set_idf(feature_names, idf)\n",
    "    \n",
    "    # clustered_vector の算出\n",
    "    model.make_clustered_vector()\n",
    "    \n",
    "    # Document セット\n",
    "    model.set_documents(lst_lst_word)\n",
    "    \n",
    "    # 平均ベクトルセット\n",
    "    model.make_meanDocumentVector()\n",
    "    \n",
    "    # sparce vector set\n",
    "    model.make_sparceDocumentVector()\n",
    "    \n",
    "    # 各ベクトルの次元が一致するか確認\n",
    "    for document in model.get_documents():\n",
    "        assert document.get_sparceMeanVector().shape[0] == num_cluster*embedding_dimension, error_display(document.get_meanWordVector().shape[0], num_cluster*embedding_dimension, \"dimension of mean vector\")\n",
    "        try:\n",
    "            document.get_meanWordVector().shape[1]\n",
    "            assert False, \"dimension is out of range\"\n",
    "        except:\n",
    "            continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training word2Vec model...\n",
      "Training clustering model...\n"
     ]
    }
   ],
   "source": [
    "test_SCDV_make_sparceDocumentVector()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python3-Ph6",
   "language": "python",
   "name": "ph6"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
